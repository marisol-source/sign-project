<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <title>Reconocimiento de Gestos</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-900 flex justify-center items-center h-screen text-white overflow-hidden">

  <!-- Video y Canvas -->
  <video id="input_video" autoplay playsinline class="absolute w-[1280px] h-[720px] rounded-xl object-cover"></video>
  <canvas id="output_canvas" class="absolute w-[1280px] h-[720px] rounded-xl object-cover"></canvas>

  <!-- Panel superior -->
  <div class="absolute top-5 left-5 bg-gray-800/90 p-4 rounded-xl shadow-lg w-72">
    <div class="flex justify-between items-center mb-2">
      <span>â±ï¸ Estado:</span>
      <span id="estado" class="font-semibold">Detectando...</span>
    </div>
    <div class="w-full h-2 bg-gray-700 rounded-full overflow-hidden mb-2">
      <div id="barra" class="h-full bg-cyan-400 transition-all duration-150" style="width:0%"></div>
    </div>
    <div class="flex justify-between items-center">
      <span>ğŸ•’ Temporizador:</span>
      <span id="timerValue" class="font-semibold">0.0 s</span>
    </div>
  </div>

  <!-- Chat lateral -->
  <div class="absolute right-5 top-1/2 transform -translate-y-1/2 w-80 h-96 bg-gray-800/90 p-4 rounded-xl shadow-lg overflow-y-auto">
    <h3 class="text-lg font-bold mb-2">ğŸª Chat de InterpretaciÃ³n</h3>
    <div id="chat" class="text-sm space-y-1 overflow-y-auto h-80"></div>
  </div>

<!-- Controles modernos con Heroicons SVG -->
<div class="absolute bottom-5 flex space-x-6 justify-center w-full">
  <button id="btnCam" class="flex items-center justify-center w-20 h-20 bg-cyan-600 hover:bg-cyan-500 active:bg-cyan-700 text-white rounded-2xl shadow-xl transition transform hover:scale-110">
    <svg xmlns="http://www.w3.org/2000/svg" class="h-10 w-10" fill="currentColor" viewBox="0 0 24 24">
      <path d="M4 5a2 2 0 00-2 2v10a2 2 0 002 2h16a2 2 0 002-2V7a2 2 0 00-2-2h-4.586l-1.707-1.707A1 1 0 0014.586 3H9.414a1 1 0 00-.707.293L7 5H4zM12 9a4 4 0 110 8 4 4 0 010-8z"/>
    </svg>
  </button>
  <button id="btnPause" class="flex items-center justify-center w-20 h-20 bg-yellow-500 hover:bg-yellow-400 active:bg-yellow-600 text-white rounded-2xl shadow-xl transition transform hover:scale-110">
    <svg xmlns="http://www.w3.org/2000/svg" class="h-10 w-10" fill="currentColor" viewBox="0 0 24 24">
      <path d="M6 4h4v16H6V4zm8 0h4v16h-4V4z"/>
    </svg>
  </button>
  <button id="btnReset" class="flex items-center justify-center w-20 h-20 bg-indigo-600 hover:bg-indigo-500 active:bg-indigo-700 text-white rounded-2xl shadow-xl transition transform hover:scale-110">
    <svg xmlns="http://www.w3.org/2000/svg" class="h-10 w-10" fill="currentColor" viewBox="0 0 24 24">
      <path d="M12 4V1L8 5l4 4V6c3.31 0 6 2.69 6 6s-2.69 6-6 6-6-2.69-6-6h-2c0 4.42 3.58 8 8 8s8-3.58 8-8-3.58-8-8-8z"/>
    </svg>
  </button>
  <button id="btnStop" class="flex items-center justify-center w-20 h-20 bg-red-600 hover:bg-red-500 active:bg-red-700 text-white rounded-2xl shadow-xl transition transform hover:scale-110">
    <svg xmlns="http://www.w3.org/2000/svg" class="h-10 w-10" fill="currentColor" viewBox="0 0 24 24">
      <path d="M6 6h12v12H6z"/>
    </svg>
  </button>
</div>


<script>
  // ==============================
  // INICIALIZACIÃ“N DE CÃMARA Y MEDIA PIPE
  // ==============================
  const CONFIG = {
    RES_W: 1280,
    RES_H: 720,
    PAUSA_LETRA: 1.5,
    PAUSA_PALABRA: 3.0,
    PAUSA_ORACION: 3.5,
    PAUSA_TEMPORIZADOR: 5.0,
    CONF_THRESH: 0.75,
    BUFFER_SIZE: 5,
    MIN_CONFIDENCE: 0.5
  };

const video = document.getElementById('input_video');
const canvas = document.getElementById('output_canvas');
const ctx = canvas.getContext('2d');

let cameraInstance = null;

async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { width: CONFIG.RES_W, height: CONFIG.RES_H, facingMode: 'user' },
    audio: false
  });
  video.srcObject = stream;
  await video.play();
  return stream;
}

const hands = new Hands({
  locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
});

hands.setOptions({
  maxNumHands: 1,
  modelComplexity: 1,
  minDetectionConfidence: CONFIG.CONF_THRESH,
  minTrackingConfidence: CONFIG.CONF_THRESH
});

hands.onResults(onResults);  // Esta funciÃ³n la definimos aparte mÃ¡s abajo

video.addEventListener('loadeddata', () => {
  canvas.width = CONFIG.RES_W;
  canvas.height = CONFIG.RES_H;
});

setupCamera().then(() => {
  cameraInstance = new Camera(video, {
    onFrame: async () => { await hands.send({ image: video }); },
    width: CONFIG.RES_W,
    height: CONFIG.RES_H
  });
  cameraInstance.start();
});


// ==============================
// VARIABLES DE ESTADO
// ==============================
const estado = document.getElementById('estado');
const barra = document.getElementById('barra');
const timerValue = document.getElementById('timerValue');
const chat = document.getElementById('chat');

let lastGestureTime = Date.now();
let lastDetected = false;
let currentTimer = 0;
let cameraOn = true;
let paused = false;

// --- Buffer para letras ---
let bufferLetras = [];
let ultimaLetra = null;


// ==============================
// FUNCIONES DE DETECCIÃ“N Y PROCESAMIENTO
// ==============================
function onResults(results) {
  if (paused) return;

  ctx.save();
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

  const now = Date.now();

  if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
    const landmarks = results.multiHandLandmarks[0];

    // Dibujar mano
    drawConnectors(ctx, landmarks, HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 3 });
    drawLandmarks(ctx, landmarks, { color: '#FF0000', lineWidth: 3, radius: 5 });

    // Enviar datos a API
    enviarLandmarksAPI(landmarks);

    lastGestureTime = now;
    lastDetected = true;
    estado.textContent = 'âœ‹ Mano detectada';
    currentTimer = 0;
  } else {
    manejarTemporizador(now);
  }

  ctx.restore();
}

// ==============================
// FUNCION AUXILIAR PARA ENVIAR LANDMARKS A API
// ==============================
function enviarLandmarksAPI(landmarks) {
  // Convertimos los landmarks a un formato simple compatible con tu API
  const payload = {
  landmarks: landmarks.map(p => ({ x: 1 - p.x, y: p.y, z: p.z }))
  };
  
  fetch("http://127.0.0.1:8001/api/test/", {
    
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(payload)
    })
    .then(res => res.json())
    .then(data => {
    if (data.letter && data.confidence >= CONFIG.MIN_CONFIDENCE) {
    // Actualizar buffer y detectar la letra mÃ¡s frecuente
    bufferLetras.push(data.letter);
    if (bufferLetras.length > CONFIG.BUFFER_SIZE) bufferLetras.shift();

      const counts = {};
      bufferLetras.forEach(l => counts[l] = (counts[l] || 0) + 1);
      const mostFrequent = Object.keys(counts).reduce((a,b) => counts[a] > counts[b] ? a : b);

      if (mostFrequent !== ultimaLetra) {
        ultimaLetra = mostFrequent;
        chat.innerHTML += `<div>ğŸ”¤ Letra detectada: ${mostFrequent} (Conf: ${Math.round(data.confidence*100)}%)</div>`;
        chat.scrollTop = chat.scrollHeight;
      }1
    }
    if (data.error) console.error("Error API:", data.error);
    })
    .catch(err => console.error("Error fetch:", err));
    }

        
// ==============================
// FUNCION AUXILIAR PARA MANEJAR TEMPORIZADOR Y ESTADO
// ==============================
function manejarTemporizador(now) {
  if (!lastDetected) return;

  currentTimer = (now - lastGestureTime) / 1000.0;
  timerValue.textContent = currentTimer.toFixed(1);

  if (currentTimer > CONFIG.PAUSA_TEMPORIZADOR) {
    estado.textContent = 'âœ… Enviando oraciÃ³n';
    chat.innerHTML += `<div>ğŸ“ OraciÃ³n completada.</div>`;
    lastDetected = false;
  } else if (currentTimer > CONFIG.PAUSA_ORACION) {
    estado.textContent = 'ğŸ—£ï¸ Fin de oraciÃ³n';
  } else if (currentTimer > CONFIG.PAUSA_PALABRA) {
    estado.textContent = 'ğŸ’¬ Fin de palabra';
  } else if (currentTimer > CONFIG.PAUSA_LETRA) {
    estado.textContent = 'ğŸ”¤ Fin de letra';
  } else {
    estado.textContent = 'â±ï¸ En pausa corta...';
  }

  barra.style.width = `${Math.min((currentTimer / CONFIG.PAUSA_TEMPORIZADOR) * 100, 100)}%`;
}

// ==============================
// EVENTOS DE BOTONES
// ==============================

// Encender/Apagar cÃ¡mara
document.getElementById('btnCam').addEventListener('click', async () => {
  if (cameraOn) {
    const tracks = video.srcObject.getTracks();
    tracks.forEach(t => t.stop());
    estado.textContent = 'ğŸ“· CÃ¡mara apagada';
    cameraOn = false;
  } else {
    await setupCamera();
    estado.textContent = 'ğŸ“¸ CÃ¡mara encendida';
    cameraOn = true;
  }
});

// Pausar/Reanudar detecciÃ³n
// Pausar/Reanudar detecciÃ³n con cambio de icono
const btnPause = document.getElementById('btnPause');
btnPause.addEventListener('click', () => {
  paused = !paused;
  if (paused) {
    estado.textContent = 'â¸ï¸ Pausado';
    btnPause.innerHTML = `
      <svg xmlns="http://www.w3.org/2000/svg" class="h-10 w-10" fill="currentColor" viewBox="0 0 24 24">
        <path d="M6 4h4v16H6V4zm8 0h4v16h-4V4z"/>
      </svg>
    `; // Icono de pausa
  } else {
    estado.textContent = 'â–¶ï¸ Reanudado';
    btnPause.innerHTML = `
      <svg xmlns="http://www.w3.org/2000/svg" class="h-10 w-10" fill="currentColor" viewBox="0 0 24 24">
        <path d="M8 5v14l11-7z"/>
      </svg>
    `; // Icono de play
  }
});


// Reiniciar temporizador y chat
document.getElementById('btnReset').addEventListener('click', () => {
  lastDetected = false;
  currentTimer = 0;
  barra.style.width = '0%';
  estado.textContent = 'ğŸ”„ Reiniciado';
  timerValue.textContent = '0.0';
  bufferLetras = [];
  ultimaLetra = null;
  chat.innerHTML = '';
});

// Detener Ãºnicamente la detecciÃ³n
document.getElementById('btnStop').addEventListener('click', () => {
  paused = true; // Solo pausa la detecciÃ³n
  estado.textContent = 'ğŸ›‘ Reconocimiento detenido';
});



// ==============================
// INICIAR CÃMARA AUTOMÃTICAMENTE AL CARGAR
// ==============================
async function iniciarCamara() {
  await setupCamera(); // Prepara el video
  cameraInstance = new Camera(video, {
    onFrame: async () => { await hands.send({ image: video }); },
    width: CONFIG.RES_W,
    height: CONFIG.RES_H
  });
  cameraInstance.start();
  cameraOn = true;
  estado.textContent = 'ğŸ“¸ CÃ¡mara encendida';
}

// Llamamos al cargar la pÃ¡gina
iniciarCamara();





</script>


</body>
</html>
